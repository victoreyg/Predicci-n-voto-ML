{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddfac2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64     79\n",
       "object     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lo primero, como siempre, es el curre (tedioso a veces) de preparar el dataframe para el modelado. Pero no desesperes,\n",
    " #en unas pocas líneas de código estaremos abordando el verdadero problema: cómo estimar el voto a partir de datos de \n",
    " #una encuesta con un modelito de ML.\n",
    "\n",
    "# Importamos librerías y cargamos el dataframe desde la url de descarga del \"Sociómtero Vasco 83, \n",
    " #Elecciones Autonómicas: previsión de voto\".\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"https://www.euskadi.eus/contenidos/ds_informes_estudios/od_24sv83/opendata/24sv83.csv\", sep = \";\")\n",
    "\n",
    "# Realizamos un análisis exploratorio básico y comprobamos, tal y como era de esperar, que no hay NA's. Los \n",
    " #profesionales del Sociómetro ya se han encargado de limpiar la BBDD por nosotros.\n",
    "\n",
    "df.head()\n",
    "df.describe()\n",
    "df.isna().sum().sum()\n",
    "\n",
    "# Además, el análisis exploratorio muestra cómo 79 de 80 variables son de tipo numérico.\n",
    "# En realidad muchas de estas variables son categóricas y esos números son los códigos asignados a esas categorías \n",
    " #en el cuestionario.\n",
    "# Total, que ahora toca un trabajito pelín artesano/manual, mirar el cuestionario y ver qué preguntas/variables son\n",
    " #categóricas y cuáles son realmente numéricas. Esta discriminación es importante para el entrenamiento de nuestro \n",
    " #modelo de ML.\n",
    "\n",
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43f368e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64     49\n",
       "object    28\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Si estás siguiendo este script es importante que mires el cuestionario para entender cómo hemos discriminado entre\n",
    " #variables categóricas y numéricas. Aquí abajo tienes el link.\n",
    "\"https://www.euskadi.eus/contenidos/ds_informes_estudios/od_24sv83/es_def/adjuntos/24sv83_gal.pdf\"\n",
    " #Hacia la mitad del pdf está la versión en castellano.\n",
    "\n",
    "# Vamos a ello, después de hacer un barrido al cuestionario, ya hemos identificado qué variables son categóricas y cuáles\n",
    " #son realmente numéricas. Hemos incluido las variables ordinales como numéricas, entendiendo que operan como una variable\n",
    " #discreta y que su procesamiento como variable numérica es más apropiado para modelar.\n",
    "# Listamos únicamente las variables categóricas ya que las numéricas/ordinales se quedarán con el dtype original (\"object\").\n",
    "\n",
    "categorical_vars = ['lurral', 'tfno', 'P0A', 'P0B', 'P01', 'P03', 'P18', 'P20', 'P21', 'P23', 'P2401', 'P2402', 'P2403', \n",
    "                    'P2501', 'P2502', 'P2503', 'P27A01', 'P27A02', 'P27A03', 'P27A04', 'P27A05', 'P27A06', 'P27A07',\n",
    "                    'P35', 'P36', 'P37', 'P38', 'P39']\n",
    "\n",
    "# Además, hemos identificado 3 variables que no aportarán nada al modelo: 'elkar', 'inkes' y 'wt' que son número \n",
    " #de entrevista, número de encuestador y una variable interna de Sociómetro, respectivamente.\n",
    "\n",
    "vars_to_drop = ['elkar', 'inkes', 'wt']\n",
    "\n",
    "# Ahora sí, cambiamos el tipo de variable para nuestras variables categóricas.\n",
    "\n",
    "df[categorical_vars] = df[categorical_vars].astype(object)\n",
    "\n",
    "# Y eliminamos las variables que no aportarán al modelo.\n",
    "\n",
    "df.drop(vars_to_drop, axis = 1, inplace = True)\n",
    "\n",
    "# Comprobamos que el cambio de tipo de variables y el droppeo se han realizado\n",
    "\n",
    "df.columns\n",
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f5f5393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vale, lo que viene ahora tiene su complejidad, pero creo que se entiende. Tenemos un problema añadido con las variables\n",
    " #que están tipificadas como numéricas. La mayoría de ellas no son numéricas puras (como 'P0B' que es la edad, por \n",
    " #ejemplo) sino que son ordinales, esto es, sus categorías de respuesta son un gradiente que sigue una escala que puede\n",
    " #ser representada numéricamente. Por ejemplo, la 'P04' es una pregunta sobre salud general del encuestado cuyas posibles \n",
    " #respuestas son 'muy buena','buena', 'regular', 'mala' y 'muy mala' que han sido codificadas del 1 al 5 respectivamente.\n",
    " #Hasta aquí bien, tiene sentido pese a ser una escala inversa (el 1 es 'muy buena' y el 5 'muy mala', pero para nuestro\n",
    " #modelo funcionará). ¿Entonces, cuál es el problema? Que hay una sexta categoría de respuesta \"No sabe-No contesta\"\n",
    " #codificada con el 6. Y \"No sabe-No contesta\" (6) no es una peor salud que \"muy mala\" (5), así que su codificación como 6 \n",
    " #puede llevar a nuestro modelo a error. Total, lo que debemos hacer es conseguir que esos \"No sabe-No contesta\", que no \n",
    " #aportan información relevante, se codifiquen de forma neutra para que no confundan al modelo. ¿Cómo lo hacemos? Pues \n",
    " #codificando esos \"No sabe-No contesta\" no como 6 sino como el promedio de respuestas (de \"muy mala\" a \"muy buena\", es \n",
    " #decir, de 1 a 5) de esa variable. Ese promedio será neutro y no confundirá al modelo.\n",
    "    \n",
    "# Y podrás pensar, vale, pues para eso tipificamos las variables como categóricas y ya está. Sí pero no en este caso.\n",
    " #Sería la solución más fácil, y probablemente la más correcta. Pero en este caso tenemos un problema, al tratarse de una\n",
    " #encuesta el número de casos es muy limitado y convertir todas las variables a categóricas dispararía la dimensionalidad \n",
    " #(una variable por categoría de respuesta) pudiendo tener casi igual número de variables que de casos. Y en ese escenario\n",
    " #el modelo no dará buenas prestaciones. Así que no es una opción, cuantas más numéricas/ordinales mejor. A recodificar.\n",
    "\n",
    "# Después de este rollazo. Pues eso, que vamos a recodificar las variables numéricas para que las respuestas tipo \"No sabe\",\n",
    " #\"No contesta\", \"Resto\"...etc tengan como código numérico el promedio de las respuestas de esa variable para que sean \n",
    " #neutras de cara al modelo. Y ya está, lo que hacen las líneas de código de debajo es eso, no te rompas la cabeza de más.\n",
    "\n",
    "numerical_3cat = ['P1001', 'P1002', 'P11', 'P16', 'P22', 'P31', 'P34']\n",
    "numerical_4cat = ['P05', 'P06', 'P07', 'P08', 'P09', 'P13', 'P17', 'P19']\n",
    "numerical_5cat = ['P04', 'P1401', 'P1402', 'P1403', 'P1404', 'P1405', 'P1501', 'P1502', 'P1503', 'P1504', 'P1505', 'P30',\n",
    "                 'P32', 'P33']\n",
    "numerical_10cat = ['P1201', 'P1202', 'P1203', 'P2601', 'P2602', 'P2603', 'P2604', 'P2605', 'P2606', 'P2607', 'P27B01', \n",
    "                   'P27B02', 'P27B03', 'P27B04', 'P27B05', 'P27B06', 'P27B07', 'P28', 'P29']\n",
    "\n",
    "for var in numerical_3cat:\n",
    "    df.loc[df[var] > 3, var] = df[var].mean()\n",
    "for var in numerical_4cat:\n",
    "    df.loc[df[var] > 4, var] = df[var].mean()\n",
    "for var in numerical_5cat:\n",
    "    df.loc[df[var] > 5, var] = df[var].mean()\n",
    "for var in numerical_10cat:\n",
    "    df.loc[df[var] > 10, var] = df[var].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e02e8a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorías P21 antes de recode: [12 1 13 14 3 6 2 7 11 4 5 10 8 9]\n",
      "Categorías P23 antes de recode: [4 1 14 3 13 5 2 8 12 6 11 9 7 10]\n",
      "\n",
      "\n",
      "Categorías P21 después de recode: ['NO SABE' 'PNV/EAJ' 'NO CONTESTA' 'RESTO' 'PSE-EE' 'PP' 'EH BILDU' 'VOX'\n",
      " 'VOTO NULO' 'PODEMOS' 'SUMAR' 'VOTO BLANCO' 'OTRO' 'NO VOTARÁ']\n",
      "Categorías P23 después de recode: ['PODEMOS' 'PNV/EAJ' 'NO CONTESTA' 'PSE-EE' 'NO SABE' 'PP + CIUDADANOS'\n",
      " 'EH BILDU' 'NO VOTÓ' 'NO PUDO VOTAR POR SER MENOR DE EDAD' 'VOX'\n",
      " 'NO PUDO VOTAR POR NO TENER DERECHO' 'VOTÓ EN BLANCO' 'OTRO' 'VOTÓ NULO']\n"
     ]
    }
   ],
   "source": [
    "# Vale, ya hemos hecho buena parte del preprocesado. Seguimos con el preprocesado de las dos variables objetivo de cara a \n",
    " #la estimación de voto y nuestro modelo de ML: intención de voto en las próximas elecciones y recuerdo de voto en las \n",
    " #elecciones pasadas, que en el cuestionario/dataframe son la 'P21' y la 'P23' resèctivamente.\n",
    " #Y lo primero que vamos a hacer es, ya que son variables categóricas con las que vamos a trabajar de cara a la estimación,\n",
    " #recodificar esas variables para que podamos ver la respuesta/categoría y no el código asociado a la misma. Toca volver a\n",
    " #echar vistacín al cuestionario, vuelta al trabajito artesano/manual. Ahí va esa recodificación.\n",
    "\n",
    "print(f\"Categorías P21 antes de recode: {df['P21'].unique()}\")\n",
    "print(f\"Categorías P23 antes de recode: {df['P23'].unique()}\")\n",
    "\n",
    "p21_dict = {1:'PNV/EAJ', 2:'EH BILDU', 3:'PSE-EE', 4:'PODEMOS', 5:'SUMAR', 6:'PP', 7:'VOX', 8:'OTRO',\n",
    "           9: 'NO VOTARÁ', 10:'VOTO BLANCO', 11:'VOTO NULO', 12:'NO SABE', 13:'NO CONTESTA', 14:'RESTO'}\n",
    "p23_dict = {1:'PNV/EAJ', 2:'EH BILDU', 3:'PSE-EE', 4:'PODEMOS', 5: 'PP + CIUDADANOS', 6:'VOX', 7:'OTRO',\n",
    "            8:'NO VOTÓ', 9:'VOTÓ EN BLANCO', 10:'VOTÓ NULO', 11:'NO PUDO VOTAR POR NO TENER DERECHO',\n",
    "            12:'NO PUDO VOTAR POR SER MENOR DE EDAD', 13:'NO SABE', 14: 'NO CONTESTA'}\n",
    "\n",
    "df['P21'] = df['P21'].replace(p21_dict)\n",
    "df['P23'] = df['P23'].replace(p23_dict)\n",
    "\n",
    "print('\\n')\n",
    "print(f\"Categorías P21 después de recode: {df['P21'].unique()}\")\n",
    "print(f\"Categorías P23 después de recode: {df['P23'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "974e685f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorías P21 después de último recode: ['NS/NC' 'PNV/EAJ' 'NO VOTARÁ' 'PSE-EE' 'PP' 'EH BILDU' 'VOX' 'VOTO NULO'\n",
      " 'PODEMOS' 'SUMAR' 'VOTO BLANCO' 'OTRO']\n",
      "Categorías P23 después de último recode: ['PODEMOS' 'PNV/EAJ' 'NS/NC' 'PSE-EE' 'PP + CIUDADANOS' 'EH BILDU'\n",
      " 'NO VOTÓ' 'VOX' 'VOTÓ EN BLANCO' 'OTRO' 'VOTÓ NULO']\n",
      "\n",
      "\n",
      "NS/NC          1220\n",
      "EH BILDU        571\n",
      "PNV/EAJ         550\n",
      "NO VOTARÁ       361\n",
      "PSE-EE          152\n",
      "PP               54\n",
      "VOTO BLANCO      29\n",
      "PODEMOS          26\n",
      "SUMAR            26\n",
      "VOX              15\n",
      "VOTO NULO        13\n",
      "OTRO             13\n",
      "Name: P21, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Venga, y ya lo ultimito antes de ponernos con el modelito de ML y explicar cómo se estima el voto. Tanto 'P21' como 'P23' \n",
    " #tienen categorías que, a efectos de estimar voto, son similares. Vamos a recodificar de nuevo. En 'P21' vamos a unificar\n",
    " #'NO VOTARÁ' y 'RESTO' como 'NO VOTARÁ', y 'NO SABE' y 'NO CONTESTA' como 'NS/NC'.\n",
    " #En 'P23' vamos a unificar 'NO VOTÓ', 'NO PUDO VOTAR POR NO TENER DERECHO' y 'NO PUDO VOTAR POR SER MENOR DE EDAD' como\n",
    " #'NO VOTÓ', y 'NO SABE' y 'NO CONTESTA' como 'NS/NC'.\n",
    "\n",
    "p21_dict = {'RESTO': 'NO VOTARÁ', 'NO SABE': 'NS/NC', 'NO CONTESTA':'NS/NC'}\n",
    "p23_dict = {'NO PUDO VOTAR POR NO TENER DERECHO': 'NO VOTÓ', 'NO PUDO VOTAR POR SER MENOR DE EDAD': 'NO VOTÓ',\n",
    "            'NO SABE': 'NS/NC', 'NO CONTESTA': 'NS/NC'}\n",
    "\n",
    "df['P21'] = df['P21'].replace(p21_dict)\n",
    "df['P23'] = df['P23'].replace(p23_dict)\n",
    "\n",
    "print(f\"Categorías P21 después de último recode: {df['P21'].unique()}\")\n",
    "print(f\"Categorías P23 después de último recode: {df['P23'].unique()}\")\n",
    "\n",
    "# Y ahora sí. ¿Sabéis cuál es el principal problema que encontramos los que nos dedicamos, o nos hemos dedicado a esto, para\n",
    " #estimar el voto? Oh, sorpresa, que hay mucho (pero mucho, 1220 casos) encuestado que no te dice a quién va a votar.\n",
    "    \n",
    "print('\\n')\n",
    "print(df['P21'].value_counts())\n",
    "\n",
    "# Total, que vamos a entrenar un modelo de ML capaz de predecir la intención de voto de 'P21' a partir del resto de\n",
    " #variables. De modo que nuestra variable objetivo será 'P21', nuestros conjuntos de train y test serán todos los casos \n",
    " #distintos de 'NS/NC' en 'P21' y nuestro conjunto de pred (a predecir) todos los casos que son 'NS/NC' en 'P21'.\n",
    " #¿Se entiende, no? Y con la salida del predict sustituiremos los 1220 casos de 'NS/NC' y, voila, ya tendremos datos de \n",
    " #intención de voto para todos los casos.\n",
    " #Y sí, es un problema peculiar, porque hemos hecho bastante preprocesado previo al split y los conjuntos de train&test y\n",
    " #pred tienen un tamaño muy similar, peeerooo no hay manera de hacerlo de otro modo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25055ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victor\\anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py:798: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  uniques = Index(uniques)\n"
     ]
    }
   ],
   "source": [
    "# Importamos librerías que vamos a necesitar en este bloque.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ahora sí, vamos con el modelo de ML. Atendiendo a los criterios apuntados justo arriba, definimos los conjuntos de \n",
    " #train&test y pred. Guardamos el conjunto de pred y trabajamos sobre el de train&test.\n",
    "\n",
    "df_train_test = df[df['P21'] != 'NS/NC']\n",
    "df_pred = df[df['P21'] == 'NS/NC']\n",
    "\n",
    "# Definimos variables predictoras (X) y variable objetivo (y) para el conjunto de train&test.\n",
    "\n",
    "X = df_train_test.drop('P21', axis = 1)\n",
    "y = df_train_test['P21']\n",
    "\n",
    "# Hacemos el split para obtener los conjuntos de train y test. Definimos un conjunto de test pequeño para optimizar al\n",
    " #máximo el entrenamiento.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=17)\n",
    "\n",
    "# Vamos a preparar nuestro conjunto de train para el fit del modelo de ML. Convertimos a one-hot las variables categóricas \n",
    " #de nuestro X_train.\n",
    "\n",
    "categorical_vars = [col for col in X_train.columns if X_train[col].dtype == 'object']\n",
    "X_train = pd.get_dummies(X_train, columns=categorical_vars)\n",
    "\n",
    "# Añadimos una categoría \"_Others\" a cada una de las variables categóricas. Como veremos más abajo servirá para garantizar \n",
    " #presencia de las mismas variables en train y test, asimilando ambos conjuntos. Anótate esta porque es buena, y te resuelve\n",
    " #un problema que es más habitual de lo que creemos.\n",
    "\n",
    "for var in categorical_vars:\n",
    "    X_train[var+\"_Others\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a281d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victor\\anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py:798: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  uniques = Index(uniques)\n"
     ]
    }
   ],
   "source": [
    "# Repetimos la última transformación del bloque anterior para X_test. Convertimos a one-hot las variables categóricas. \n",
    "\n",
    "X_test = pd.get_dummies(X_test, columns=categorical_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "331196bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape de X_train: (1448, 272) | shape de X_test: (362, 272)\n"
     ]
    }
   ],
   "source": [
    "# Apoyándonos en las categorías \"var+_Others\" (añadidas más arriba) creamos, eliminamos y transformamos variables para \n",
    " #asimilar los conjuntos de train y test. Lo dicho antes, anótatela porque es buena y resuelve.\n",
    "\n",
    "vars_no_incommon_train = [var for var in X_train.columns if var not in X_test.columns]\n",
    "vars_no_incommon_test = [var for var in X_test.columns if var not in X_train.columns]\n",
    "\n",
    "for var in vars_no_incommon_train:\n",
    "    X_test[var] = 0\n",
    "for var in vars_no_incommon_test:\n",
    "    X_test = X_test.drop(var, axis = 1)\n",
    "    X_test[var+\"_Others\"] = 1\n",
    "\n",
    "X_train_columnssorted = sorted(X_train.columns)\n",
    "X_train = X_train[X_train_columnssorted]\n",
    "X_test = X_test[X_train_columnssorted]\n",
    "\n",
    "# Me guardo un copia de X_train para más adelante\n",
    "\n",
    "X_train_copy = X_train\n",
    "\n",
    "# Comprobamos los shape de X_train y X_test para corroborar que todo está OK.\n",
    "\n",
    "print(f'shape de X_train: {X_train.shape} | shape de X_test: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf90ec48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos librerías que vamos a necesitar en este bloque.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Volvemos al conjunto de train. Normalizamos las variables numéricas en X_train.\n",
    "\n",
    "variables_to_norm = [col for col in X_train.columns if X_train[col].dtype == 'int64']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[variables_to_norm])\n",
    "\n",
    "X_train[variables_to_norm] = scaler.transform(X_train[variables_to_norm])\n",
    "\n",
    "# Transformamos X_train en arreglo numpy para poder entrenar nuestro modelo de ML.\n",
    "\n",
    "X_train = X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac13e67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repetimos las transformaciones del bloque anterior para X_test. Importante, la normalización con el scaler de train.\n",
    "\n",
    "# Normalizamos las variables numéricas en X_test.\n",
    "\n",
    "X_test[variables_to_norm] = scaler.transform(X_test[variables_to_norm])\n",
    "\n",
    "# Transformamos X_test en arreglo numpy para poder entrenar nuestro modelo de ML.\n",
    "\n",
    "X_test = X_test.values\n",
    "\n",
    "# Y ya está, todo listo para nuestro modelo de ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de4b0c72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    EH BILDU       0.95      0.93      0.94       112\n",
      "   NO VOTARÁ       0.91      1.00      0.95        87\n",
      "        OTRO       0.00      0.00      0.00         2\n",
      "     PNV/EAJ       0.90      0.95      0.93       104\n",
      "     PODEMOS       0.67      0.33      0.44         6\n",
      "          PP       1.00      0.78      0.88         9\n",
      "      PSE-EE       0.73      0.92      0.81        26\n",
      "       SUMAR       1.00      0.29      0.44         7\n",
      " VOTO BLANCO       1.00      0.20      0.33         5\n",
      "   VOTO NULO       0.00      0.00      0.00         3\n",
      "         VOX       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.90       362\n",
      "   macro avg       0.74      0.58      0.61       362\n",
      "weighted avg       0.90      0.90      0.89       362\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victor\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Victor\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Victor\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Importamos librerías necesarias para este bloque\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Vamos a entrenar nuestro modelo de ML. Random Forest suele dar buenas prestaciones en este tipo de problemas de\n",
    " #clasificación. Utilizaremos técnicas de grid para optimizar algunos de los hiperparámetros y afinar el modelo.\n",
    "    \n",
    "# Instanciamos nuestro modelo (el parámetro 'class_weight' corregirá el desbalanceo de categorías a predecir).\n",
    "\n",
    "rf_classifier = RandomForestClassifier(class_weight='balanced', random_state=17)\n",
    "\n",
    "# Definimos los hiperparámetros a optimizar.\n",
    "\n",
    "param_grid = {'n_estimators': [100, 200, 300],'max_depth': [None, 10, 25, 50]}\n",
    "\n",
    "# Creamos el objeto de grid y entrenamos nuestro modelo.\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Visualizamos prestaciones del modelo sobre el conjunto de test.\n",
    "\n",
    "y_predicted = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "366ffc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# El modelo alcanza un accuracy global del 90%, acertando especialmente en el voto a las\n",
    " #opciones mayoritarias (y es normal, ha podido entrenar con más casos de estas opciones). Falla ligeramente o \n",
    " #infrarepresenta con Podemos, Sumar, voto blanco, voto nulo y Vox. Con todo son unas métricas bastante aceptables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd3ec92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   param_n_estimators param_max_depth  mean_test_score\n",
      "0                 100            None         0.883983\n",
      "1                 200            None         0.883985\n",
      "2                 300            None         0.884677\n",
      "3                 100              10         0.892951\n",
      "4                 200              10         0.895717\n",
      "5                 300              10         0.893645\n",
      "6                 100              25         0.883293\n",
      "7                 200              25         0.884675\n",
      "8                 300              25         0.884677\n",
      "9                 100              50         0.883983\n",
      "10                200              50         0.883985\n",
      "11                300              50         0.884677\n"
     ]
    }
   ],
   "source": [
    "# Quizá podamos pensar que el modelo puede mejorar con otros hiperparámetros. Visualizamos rápidamente las prestaciones \n",
    " #para los distintos hiperparámetros probados.\n",
    "\n",
    "results_grid = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "relevant_columns = ['param_n_estimators', 'param_max_depth', 'mean_test_score']\n",
    "results_grid = results_grid[relevant_columns]\n",
    "\n",
    "print(results_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a8368c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observamos que las prestaciones del modelo varían mínimamente de unos hiperparámetros a otros, y que a partir de una\n",
    " #profundidad de 25 las variaciones son residuales. Total, tenemos hiperparámetros los óptimos y un modelo razonablemente\n",
    " #bueno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1feccf1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victor\\anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py:798: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  uniques = Index(uniques)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape de X_train_copy: (1448, 272) | shape de df_pred: (1220, 272)\n"
     ]
    }
   ],
   "source": [
    "# Vale, pues ahora sí que sí, vamos a ejecutar el modelo sobre el conjunto pred para predecir las opciones de voto que\n",
    " #sustituirán a los 1220 NS/NC.\n",
    "# Lo primero que tenemos que hacer es aplicar sobre el conjunto pred (haremos una copia llamada 'df_for_pred') todas las \n",
    " #transformaciones que hicimos sobre el conjunto de train (recordad que guardé una copia llamada 'X_train_copy'), para \n",
    " #garantizar mismo formato y características en ambos conjuntos.\n",
    "\n",
    "# Eliminamos la variable objetivo/a predecir.\n",
    "\n",
    "df_for_pred = df_pred.drop('P21', axis = 1)\n",
    "\n",
    "# Convertimos a one-hot las variables categóricas.\n",
    "\n",
    "df_for_pred = pd.get_dummies(df_for_pred, columns=categorical_vars)\n",
    "\n",
    "# Añadimos una categoría \"_Others\" a cada una de las variables categóricas.\n",
    "\n",
    "for var in categorical_vars:\n",
    "    df_for_pred[var+\"_Others\"] = 0\n",
    "\n",
    "# Apoyándonos en las categorías \"var+_Others\" creamos, eliminamos y transformamos variables para \n",
    " #asimilar los conjuntos de train y pred.\n",
    "\n",
    "vars_no_incommon_train = [var for var in X_train_copy.columns if var not in df_for_pred.columns]\n",
    "vars_no_incommon_pred = [var for var in df_for_pred.columns if var not in X_train_copy.columns]\n",
    "\n",
    "for var in vars_no_incommon_train:\n",
    "    df_for_pred[var] = 0\n",
    "for var in vars_no_incommon_pred:\n",
    "    df_for_pred = df_for_pred.drop(var, axis = 1)\n",
    "    df_for_pred[var+\"_Others\"] = 1\n",
    "\n",
    "df_for_pred = df_for_pred[X_train_columnssorted]\n",
    "\n",
    "# Comprobamos los shape de X_train_copy y df_for_pred para corroborar que todo está OK.\n",
    "\n",
    "print(f'shape de X_train_copy: {X_train_copy.shape} | shape de df_pred: {df_for_pred.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ac6dccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EH BILDU:106\n",
      "NO VOTARÁ:762\n",
      "PNV/EAJ:240\n",
      "PODEMOS:2\n",
      "PP:13\n",
      "PSE-EE:67\n",
      "SUMAR:1\n",
      "VOTO BLANCO:29\n"
     ]
    }
   ],
   "source": [
    "# Comprobados los shape, todo OK. Seguimos con las últimas transformaciones.\n",
    "# Normalizamos las variables numéricas en df_pred.\n",
    "\n",
    "df_for_pred[variables_to_norm] = scaler.transform(df_for_pred[variables_to_norm])\n",
    "\n",
    "# Transformamos df_pred en arreglo numpy para poder entrenar nuestro modelo de ML.\n",
    "\n",
    "df_for_pred = df_for_pred.values\n",
    "\n",
    "# Y ya está, todo listo para ejecutar el predict. Vamos a ello.\n",
    "\n",
    "y_predicted = grid_search.predict(df_for_pred)\n",
    "\n",
    "# Observamos cómo ha ido el predict.\n",
    "\n",
    "opciones, conteos = np.unique(y_predicted, return_counts=True)\n",
    "for opcion, conteo in zip(opciones, conteos):\n",
    "    print(f'{opcion}:{conteo}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f51fd023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victor\\AppData\\Local\\Temp\\ipykernel_10388\\1516723314.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pred['P21'] = y_predicted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NO VOTARÁ      1123\n",
       "PNV/EAJ         790\n",
       "EH BILDU        677\n",
       "PSE-EE          219\n",
       "PP               67\n",
       "VOTO BLANCO      58\n",
       "PODEMOS          28\n",
       "SUMAR            27\n",
       "VOX              15\n",
       "VOTO NULO        13\n",
       "OTRO             13\n",
       "Name: P21, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bueno, pues solo nos queda sustituir los nuevos datos de la salida del predict. Vaya, tenemos que sustituir\n",
    "#los 'NS/NC' del conjunto original de pred por nuestro y_predicted. Y ya estaría. O casi.\n",
    "#A modo de recordatorio, que ya a estas alturas nos habremos perdido. Los dos subconjuntos originales que tenemos limpitos\n",
    "#y sin cacharreo más allá de los recodes y renombrados de categorías de respuesta son 'df_train_test' y 'df_pred' (los\n",
    "#tienes al inicio de la celda 6). Después de sustituir los 'NS/NC' haremos un concat y ya estaría. O casi.\n",
    "\n",
    "df_pred['P21'] = y_predicted\n",
    "\n",
    "df_all = pd.concat([df_train_test, df_pred])\n",
    "\n",
    "#Y después de todo esto...volvemos a visualizar 'P21' y, magia, los 1220 'NS/NC' han desparecido (han sido sustituidos por\n",
    " #nuestras predicciones) y ya tenemos intención de voto para todos los casos. \n",
    "\n",
    "df_all['P21'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3437f4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de casos de df_all: 2504\n"
     ]
    }
   ],
   "source": [
    "# Pues ya estaría, ¿no?, ya tenemos la estimación de voto.\n",
    " #Pues no. Tenemos lo que los encuestados nos dicen que van a votar, los 3030 encuestados, que ya es (antes de nuestro \n",
    " #modelo de ML sólo lo teníamos para 1810 casos, ya que había 1220 'NS/NC'). Vaya, tenemos la intención de voto. Pero la \n",
    " #estimación de voto es algo más compleja. ¿Por qué? Porque hay gente que dice a quién va a votar pero finalmente no vota.\n",
    " #Y porque hay gente que miente sobre a quién va a votar. ¿Y tenemos manera de saber quién nos miente? No exactamente\n",
    " #quién, sino en qué medida nos están mintiendo para cada una de las opciones de voto. Y en función de la medida en que\n",
    " #nos están mintiendo, podemos corregir (ponderando) el voto a esas opciones.\n",
    "\n",
    "# Venga, vamos a ello, que mola bastante. Ya estamos casi terminandooo!\n",
    "\n",
    "# Lo primero, la gente que dice que va a votar pero termina por no votar. Tenemos una variable que nos da alguna\n",
    " #pista al respecto, la 'P20' es una pregunta sobre la probabilidad de ir a votar. Pues bien, vamos a quedarnos con aquellos\n",
    " #que responden que acudirán a votar 'Sí, seguro' y 'Probablemente sí', que se correspoden con los códigos de respuesta 1 y\n",
    " #2 respectivamente. Así nuestra estimación de voto incluirá sólo a aquellos que tienen más probabilidad de ir a votar,\n",
    " #dejando fuera a aquellos que probablemente no votarán. Total, que hay que filtrar nustro df.\n",
    "\n",
    "df_all = df_all[(df_all['P20'] == 1) | (df_all['P20'] == 2)]\n",
    "print(f'Número de casos de df_all: {len(df_all)}')\n",
    "\n",
    "# El número de casos se ha reducido significativamente, de 3030 a 2504, nos hemos quitado un buen numero de abstencionistas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bac0719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P23          EH BILDU  NO VOTÓ  NS/NC  OTRO  PNV/EAJ  PODEMOS  \\\n",
      "P21                                                             \n",
      "EH BILDU          541       10     25     1       39       42   \n",
      "NO VOTARÁ          20       58    401     5       87       31   \n",
      "OTRO                0        1      2     4        0        0   \n",
      "PNV/EAJ             5       22     38     0      687        1   \n",
      "PODEMOS             2        0      2     1        0       20   \n",
      "PP                  1        4      6     0        9        0   \n",
      "PSE-EE              0        6      9     1        8        7   \n",
      "SUMAR               1        2      3     1        1       16   \n",
      "VOTO BLANCO         1        0     14     1        9        1   \n",
      "VOTO NULO           0        2      0     2        2        0   \n",
      "VOX                 0        1      0     0        2        1   \n",
      "Total             571      106    500    16      844      119   \n",
      "\n",
      "P23          PP + CIUDADANOS  PSE-EE  VOTÓ EN BLANCO  VOTÓ NULO  VOX  Total  \n",
      "P21                                                                          \n",
      "EH BILDU                   0       7               1          1    0    667  \n",
      "NO VOTARÁ                  7      29               3          3    2    646  \n",
      "OTRO                       0       0               1          0    0      8  \n",
      "PNV/EAJ                    5      12               0          0    1    771  \n",
      "PODEMOS                    0       3               0          0    0     28  \n",
      "PP                        41       3               0          0    1     65  \n",
      "PSE-EE                     0     184               0          0    0    215  \n",
      "SUMAR                      0       2               0          0    0     26  \n",
      "VOTO BLANCO                0       1              25          0    0     52  \n",
      "VOTO NULO                  0       0               0          6    0     12  \n",
      "VOX                        2       0               0          0    8     14  \n",
      "Total                     55     241              30         10   12   2504  \n"
     ]
    }
   ],
   "source": [
    "# Y ahora a poner en funcionamiento el detector de mentiras. Decíamos antes que lo único que podemos saber al respecto es \n",
    " #la medida en que nos están mintiendo, en conjunto, para cada una de las opciones de voto. ¿Y cómo podemos saberlo?\n",
    " #Pues con el único dato real y cuantificable que tenemos, los resultados (reales) de las pasadas elecciones. Y comparando \n",
    " #ese porcentaje real de voto con el recuerdo de voto de las pasadas elecciones ('P23') de la encuesta observaremos \n",
    " #infrarecuerdos y sobrerecuerdos de voto que nos permitirán ponderar los casos. Y ya tendríamos nuestra estimación.\n",
    "\n",
    "# Pero para, para. Vamos por pasos. Lo primero que necesitamos es el cruce entre la intención de voto ('P21') y el recuerdo\n",
    " #de voto de las pasadas elecciones ('P23'). Vaya, una tabla de contingencia.\n",
    "\n",
    "vote_table = pd.crosstab(df_all['P21'], df_all['P23'], margins = True, margins_name=\"Total\")\n",
    "\n",
    "print(vote_table)\n",
    "\n",
    "# Hecho, ya estamos para terminar. Lo haremos sobre excel, por dos razones. Una, soy un nostálgico y siempre he rematado las\n",
    " #estimaciones de voto en excel. Dos, creo que objetivamente es más sencillo y más visual.\n",
    "\n",
    "# Así que nos llevamos esa tabla de contingencia a excel.\n",
    "\n",
    "vote_table.to_excel('vote_table.xlsx', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
